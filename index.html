<!DOCTYPE html>
<html>
<head>
  <title>Iron Man Eye HUD</title>
  <meta charset="UTF-8" />
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <style>
    body {
      margin: 0;
      overflow: hidden;
      background: black;
    }
    video, canvas {
      position: absolute;
      width: 100vw;
      height: 100vh;
      object-fit: cover;
    }
    .hud-text, .lock-msg {
      position: absolute;
      font-family: monospace;
      color: cyan;
      font-size: 18px;
      background: rgba(0,0,0,0.6);
      padding: 8px;
      border-radius: 10px;
    }
    .hud-text { top: 10px; left: 10px; }
    .lock-msg {
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      font-size: 22px;
      color: red;
      display: none;
    }
  </style>
</head>
<body>
  <div class="hud-text">üéôÔ∏è Say Commands: "activate laser", "shutdown", "zoom in"</div>
  <div class="lock-msg" id="lockMsg">üîê Face Not Detected</div>
  <video class="input_video" autoplay muted playsinline></video>
  <canvas class="output_canvas"></canvas>

  <script>
    const videoElement = document.querySelector('.input_video');
    const canvasElement = document.querySelector('.output_canvas');
    const canvasCtx = canvasElement.getContext('2d');
    const lockMsg = document.getElementById('lockMsg');

    let faceDetected = false;

    const speak = (text) => {
      const msg = new SpeechSynthesisUtterance(text);
      msg.rate = 1;
      window.speechSynthesis.speak(msg);
    };

    const faceMesh = new FaceMesh({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
    });

    faceMesh.setOptions({
      maxNumFaces: 1,
      refineLandmarks: true,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });

    faceMesh.onResults((results) => {
      canvasElement.width = videoElement.videoWidth;
      canvasElement.height = videoElement.videoHeight;
      canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
      canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);

      if (results.multiFaceLandmarks.length > 0) {
        if (!faceDetected) {
          faceDetected = true;
          lockMsg.style.display = "none";
          speak("Access granted. Hello, Commander.");
          startVoiceRecognition();
        }

        const landmarks = results.multiFaceLandmarks[0];
        const drawEye = (range, color) => {
          for (let i = range[0]; i <= range[1]; i++) {
            const pt = landmarks[i];
            const x = pt.x * canvasElement.width;
            const y = pt.y * canvasElement.height;
            canvasCtx.beginPath();
            canvasCtx.arc(x, y, 3, 0, 2 * Math.PI);
            canvasCtx.fillStyle = color;
            canvasCtx.shadowBlur = 5;
            canvasCtx.shadowColor = color;
            canvasCtx.fill();
          }
        };
        drawEye([133, 144], 'cyan');  // Left eye
        drawEye([362, 373], 'red');   // Right eye

        const center = landmarks[1];
        canvasCtx.beginPath();
        canvasCtx.arc(center.x * canvasElement.width, center.y * canvasElement.height, 40, 0, 2 * Math.PI);
        canvasCtx.strokeStyle = 'rgba(0,255,255,0.6)';
        canvasCtx.lineWidth = 2;
        canvasCtx.stroke();
      } else {
        faceDetected = false;
        lockMsg.style.display = "block";
      }
    });

    const camera = new Camera(videoElement, {
      onFrame: async () => {
        await faceMesh.send({ image: videoElement });
      },
      width: 640,
      height: 480
    });
    camera.start();

    // ---------------- VOICE COMMAND ----------------
    let recognition;
    function startVoiceRecognition() {
      if (!('webkitSpeechRecognition' in window)) {
        speak("Voice recognition not supported in this browser.");
        return;
      }
      recognition = new webkitSpeechRecognition();
      recognition.lang = 'en-US';
      recognition.continuous = true;
      recognition.interimResults = false;

      recognition.onresult = (event) => {
        const command = event.results[event.results.length - 1][0].transcript.trim().toLowerCase();
        console.log("Heard:", command);
        handleVoiceCommand(command);
      };

      recognition.onerror = (e) => {
        console.error('Voice error:', e);
      };

      recognition.start();
    }

    function handleVoiceCommand(cmd) {
      if (cmd.includes("activate laser")) {
        speak("Laser activated.");
        alert("üöÄ Pew Pew! Lasers activated!");
      } else if (cmd.includes("shutdown")) {
        speak("Shutting down.");
        alert("üí§ System shutting down...");
        recognition.stop();
      } else if (cmd.includes("zoom in")) {
        speak("Zooming in.");
        canvasElement.style.transform = "scale(1.2)";
        setTimeout(() => canvasElement.style.transform = "scale(1)", 2000);
      } else {
        speak("Command not recognized.");
      }
    }
  </script>
</body>
</html>